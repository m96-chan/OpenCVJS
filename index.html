<html lang="ja">
<head>
    <title>OpenCVJs</title>
    <script async src=https://docs.opencv.org/4.5.2/opencv.js onload="onOpenCvReady()"></script>
    <script src="https://docs.opencv.org/4.5.2/utils.js"></script>
</head>
<body>
<div>
    <video id="web-camera-video" autoplay muted playsinline></video>
</div>
<div>
    <canvas id="web-camera-render"></canvas>
</div>
<script>
    const video = document.querySelector("#web-camera-video");
    navigator.mediaDevices.getUserMedia({
        audio: false,
        video: {
            width: 1280,
            height: 720
        }
    }).then(
        (s) => {
            video.srcObject = s;
            video.onloadedmetadata = _ => video.play().then(_ => {
                video.height = video.videoHeight;
                video.width = video.videoWidth;
                run();
            }).catch(
                e => console.error(e)
            );
        }
    ).catch(e => {
        console.error(e);
    })


    let cvLoaded = false;
    let src = null;
    let dst = null;
    let gray = null;
    let cap = null;
    let classifier = null;
    onOpenCvReady = () => {
        cv['onRuntimeInitialized'] = () => {
            console.log(cv.getBuildInformation());
            cvLoaded = true;
            classifier = new cv.CascadeClassifier();
            gray = new cv.Mat();
            const utils = new Utils('errorMessage');
            const faceCascadeFile = 'haarcascade_frontalface_default.xml';
            //const faceCascadeFile = 'haarcascade_eye.xml';
            // use createFileFromUrl to "pre-build" the xml
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                classifier.load(faceCascadeFile);
            });
        }
    }

    const FPS = 30;
    const run = () => {
        if (!cvLoaded) {
            setTimeout(run, 100);
        }
        if (cap === null) {
            cap = new cv.VideoCapture(video);
        }
        if (src === null) {
            src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        }
        if (dst === null) {
            dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        }
        const begin = Date.now();
        cap.read(src);
        src.copyTo(dst);
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        let faces = new cv.RectVector();
        // default設定
        //classifier.detectMultiScale(gray, faces ,1.1, 3, 0, msize, msize);
        //classifier.detectMultiScale(gray, faces ,2, 2);
        classifier.detectMultiScale(gray, faces, 1.5, 3);

        for (let i = 0; i < faces.size(); ++i) {
            let face = faces.get(i);
            let roi = dst.roi(face);
            mosaic(roi);
            // let point1 = new cv.Point(face.x, face.y);
            // let point2 = new cv.Point(face.x + face.width, face.y + face.height);
            // cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
        }
        cv.imshow('web-camera-render', dst);

        const delay = 1000 / FPS - (Date.now() - begin);
        setTimeout(run, delay);
    }

    const mosaic = (target) => {
        const rows = target.rows;
        const cols = target.cols;
        const buff = new cv.Mat()
        cv.resize(target, buff, new cv.Size(0, 0), 1.0 / 14, 1.0 / 14, cv.INTER_NEAREST);
        cv.resize(buff, target, new cv.Size(cols, rows), 0, 0, cv.INTER_NEAREST);
        buff.delete();
    }
</script>
</body>
</html>